{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "def calculate_recency_scores(df):\n",
    "    df_copy = df.copy()\n",
    "    current_date = datetime.now()\n",
    "    \n",
    "    for idx, row in df_copy.iterrows():\n",
    "        scores = calculate_row_recency_scores(row, current_date)\n",
    "        \n",
    "        for score_col, score_val in scores.items():\n",
    "            df_copy.at[idx, score_col] = score_val\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def calculate_row_recency_scores(row, current_date):\n",
    "    scores = {}\n",
    "    \n",
    "    address_indices = []\n",
    "    n = 0\n",
    "    max_checks = 10  \n",
    "    \n",
    "    while n < max_checks:\n",
    "        address_col = f'Address.{n}.completeAddress'\n",
    "        if address_col in row and pd.notna(row[address_col]) and str(row[address_col]).strip() != '':\n",
    "            address_indices.append(n)\n",
    "        n += 1\n",
    "    \n",
    "    if not address_indices:\n",
    "        return scores\n",
    "    \n",
    "    all_address_types = []\n",
    "    for i in address_indices:\n",
    "        types = get_address_types(row, i)\n",
    "        all_address_types.extend(types)\n",
    "    \n",
    "    unique_types_count = len(set(all_address_types)) if all_address_types else 1\n",
    "    \n",
    "    for i in address_indices:\n",
    "        score = calculate_single_address_score(row, i, current_date, unique_types_count)\n",
    "        address_text = str(row[f'Address.{i}.completeAddress']).strip()\n",
    "        \n",
    "        scores[f'Address.{i}_recency_score'] = round(score, 2)\n",
    "        scores[f'Address.{i}_address_text'] = address_text\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def get_address_types(row, address_index):\n",
    "  \n",
    "    prefix = f'Address.{address_index}'\n",
    "    types_field = f'{prefix}.addressType'\n",
    "    \n",
    "    if types_field not in row or pd.isna(row[types_field]):\n",
    "        return []\n",
    "    \n",
    "    types_value = row[types_field]\n",
    "    \n",
    "    if isinstance(types_value, list):\n",
    "        return types_value\n",
    "    elif isinstance(types_value, str):\n",
    "        types_value = types_value.strip()\n",
    "        if types_value.startswith('[') and types_value.endswith(']'):\n",
    "            try:\n",
    "                return ast.literal_eval(types_value)\n",
    "            except:\n",
    "                return [types_value.strip(\"[]'\\\"\")]\n",
    "        else:\n",
    "            return [types_value]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def calculate_single_address_score(row, address_index, current_date, unique_types_count):\n",
    "    \"\"\"\n",
    "    Calculate recency score for a single address\n",
    "    \"\"\"\n",
    "    prefix = f'Address.{address_index}'\n",
    "    \n",
    "    # 1. Temporal Score (40%)\n",
    "    temporal_score = calculate_temporal_score(row, prefix, current_date)\n",
    "    \n",
    "    # 2. Frequency Score (25%)\n",
    "    frequency_score = calculate_frequency_score(row, prefix)\n",
    "    \n",
    "    # 3. Usage Pattern Score (20%)\n",
    "    pattern_score = calculate_pattern_score(row, address_index)\n",
    "    \n",
    "    # 4. Consistency Score (10%)\n",
    "    consistency_score = calculate_consistency_score(unique_types_count)\n",
    "    \n",
    "    # 5. Quality Impact (5%)\n",
    "    quality_score = calculate_quality_score(row, prefix)\n",
    "    \n",
    "    # Final weighted calculation\n",
    "    final_score = (\n",
    "        temporal_score * 0.40 +\n",
    "        frequency_score * 0.25 +\n",
    "        pattern_score * 0.20 +\n",
    "        consistency_score * 0.10 +\n",
    "        quality_score * 0.05\n",
    "    )\n",
    "    \n",
    "    return final_score\n",
    "\n",
    "def calculate_temporal_score(row, prefix, current_date):\n",
    "    delivery_date_field = f'{prefix}.lastDeliveryDate'\n",
    "    \n",
    "    if delivery_date_field not in row or pd.isna(row[delivery_date_field]):\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        delivery_date = pd.to_datetime(row[delivery_date_field])\n",
    "        \n",
    "        if delivery_date.tz is not None:\n",
    "            delivery_date = delivery_date.tz_convert('UTC').tz_localize(None)\n",
    "        \n",
    "        if hasattr(current_date, 'tz') and current_date.tz is not None:\n",
    "            current_date = current_date.tz_localize(None)\n",
    "        \n",
    "        days_diff = (current_date - delivery_date).days\n",
    "        \n",
    "        if days_diff <= 7:\n",
    "            return 100\n",
    "        elif days_diff <= 90:\n",
    "            return 50 + 35 * math.exp(-0.05 * (days_diff - 7))\n",
    "        elif days_diff <= 365:\n",
    "            return max(5, 20 - 15 * ((days_diff - 90) / 275))\n",
    "        else:\n",
    "            return 5\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "def calculate_frequency_score(row, prefix):\n",
    "    times_seen_field = f'{prefix}.timesSeen'\n",
    "    \n",
    "    if times_seen_field not in row or pd.isna(row[times_seen_field]):\n",
    "        times_seen = 0\n",
    "    else:\n",
    "        times_seen = int(row[times_seen_field])\n",
    "    \n",
    "    if times_seen == 1:\n",
    "        return 40\n",
    "    elif times_seen <= 3:\n",
    "        return 40 + (times_seen - 1) * 20\n",
    "    elif times_seen <= 10:\n",
    "        return 80 + (times_seen - 3) * 2.4\n",
    "    else:\n",
    "        return min(100, 97 + (times_seen - 10) * 0.3)\n",
    "\n",
    "def calculate_pattern_score(row, address_index):\n",
    "    \"\"\"\n",
    "    Calculate usage pattern score based on address type\n",
    "    \"\"\"\n",
    "    address_types = get_address_types(row, address_index)\n",
    "    \n",
    "    type_scores = {\n",
    "        'logisticsAddress': 90,        # High recency importance - active delivery\n",
    "        'transportDlAddress': 75,      # Moderate - government registered, changes occasionally  \n",
    "        'taxAddress': 80,              # High - tax filing addresses change when business moves\n",
    "        'businessAddress': 85,         # High - business operations, moderate change frequency\n",
    "        'temporaryAddress': 95,        # Highest - by definition temporary\n",
    "        'billingAddress': 70,          # Moderate - billing addresses change less frequently\n",
    "        'permanentAddress': 40         # Low - permanent by definition\n",
    "    }\n",
    "    \n",
    "    if not address_types:\n",
    "        return 60  \n",
    "    \n",
    "    scores = [type_scores.get(addr_type, 60) for addr_type in address_types]\n",
    "    return max(scores)\n",
    "\n",
    "def calculate_consistency_score(unique_types_count):\n",
    "    if unique_types_count == 1:\n",
    "        return 85\n",
    "    elif unique_types_count == 2:\n",
    "        return 70\n",
    "    elif unique_types_count == 3:\n",
    "        return 55\n",
    "    else:\n",
    "        return 40\n",
    "\n",
    "def calculate_quality_score(row, prefix):\n",
    "    completeness_field = f'{prefix}.completeAddress.addressCompletenessScore'\n",
    "    \n",
    "    if completeness_field not in row or pd.isna(row[completeness_field]):\n",
    "        return 40  # Default low score\n",
    "    \n",
    "    completeness = float(row[completeness_field])\n",
    "    \n",
    "    if completeness >= 80:\n",
    "        return 100\n",
    "    elif completeness >= 60:\n",
    "        return 85\n",
    "    elif completeness >= 40:\n",
    "        return 70\n",
    "    elif completeness >= 20:\n",
    "        return 55\n",
    "    else:\n",
    "        return 40\n",
    "\n",
    "def analyze_results(df_with_scores):\n",
    "    score_cols = [col for col in df_with_scores.columns if col.endswith('_recency_score')]\n",
    "    address_text_cols = [col for col in df_with_scores.columns if col.endswith('_address_text')]\n",
    "    \n",
    "    if not score_cols:\n",
    "        print(\"No recency scores found!\")\n",
    "        return\n",
    "    \n",
    "    print(\"=== RECENCY SCORE ANALYSIS ===\\n\")\n",
    "    \n",
    "    all_scores = []\n",
    "    for col in score_cols:\n",
    "        all_scores.extend(df_with_scores[col].dropna().tolist())\n",
    "    \n",
    "    if all_scores:\n",
    "        print(f\"Total addresses scored: {len(all_scores)}\")\n",
    "        print(f\"Average recency score: {np.mean(all_scores):.2f}\")\n",
    "        print(f\"Score range: {min(all_scores):.2f} - {max(all_scores):.2f}\")\n",
    "        print(f\"Standard deviation: {np.std(all_scores):.2f}\\n\")\n",
    "        \n",
    "        print(\"Score Distribution:\")\n",
    "        print(f\"Excellent (90-100): {sum(1 for s in all_scores if s >= 90)} addresses\")\n",
    "        print(f\"Good (75-89): {sum(1 for s in all_scores if 75 <= s < 90)} addresses\")\n",
    "        print(f\"Fair (60-74): {sum(1 for s in all_scores if 60 <= s < 75)} addresses\")\n",
    "        print(f\"Poor (40-59): {sum(1 for s in all_scores if 40 <= s < 60)} addresses\")\n",
    "        print(f\"Very Poor (0-39): {sum(1 for s in all_scores if s < 40)} addresses\")\n",
    "    \n",
    "    print(f\"\\n=== SAMPLE RESULTS ===\")\n",
    "    \n",
    "    display_cols = ['name', 'email']\n",
    "    \n",
    "    # Add score and address pairs in order\n",
    "    for i in range(10):  # Check up to Address.9\n",
    "        score_col = f'Address.{i}_recency_score'\n",
    "        addr_col = f'Address.{i}_address_text'\n",
    "        if score_col in df_with_scores.columns:\n",
    "            display_cols.extend([score_col, addr_col])\n",
    "    \n",
    "    available_cols = [col for col in display_cols if col in df_with_scores.columns]\n",
    "    \n",
    "    sample_df = df_with_scores[available_cols].head(10)\n",
    "    \n",
    "    # Display in a more readable format\n",
    "    for idx, row in sample_df.iterrows():\n",
    "        print(f\"\\n--- {row['name']} ({row['email']}) ---\")\n",
    "        for col in available_cols:\n",
    "            if col.endswith('_recency_score') and pd.notna(row[col]):\n",
    "                addr_idx = col.split('.')[1].split('_')[0]\n",
    "                addr_text_col = f'Address.{addr_idx}_address_text'\n",
    "                addr_text = row.get(addr_text_col, 'N/A')\n",
    "                print(f\"  Score: {row[col]:.2f} | Address: {str(addr_text)[:80]}...\")\n",
    "        \n",
    "        if idx >= 4:  # Show only first 5 rows in detail\n",
    "            break\n",
    "    \n",
    "    return df_with_scores[score_cols].describe()\n",
    "\n",
    "# Main execution function\n",
    "def run_recency_analysis(file_path):\n",
    "    \"\"\"\n",
    "    Main function to run the complete recency analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the data\n",
    "        print(\"Loading data...\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "        \n",
    "        # Check for address columns\n",
    "        address_cols = [col for col in df.columns if 'Address.' in col and 'completeAddress' in col]\n",
    "        print(f\"Found {len(address_cols)} address columns: {address_cols[:5]}...\")  # Show first 5\n",
    "        \n",
    "        # Calculate recency scores\n",
    "        print(\"\\nCalculating recency scores...\")\n",
    "        df_with_scores = calculate_recency_scores(df)\n",
    "        \n",
    "        # Analyze results\n",
    "        stats = analyze_results(df_with_scores)\n",
    "        \n",
    "        return df_with_scores, stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the analysis\n",
    "    file_path = \"DCB_AlternateAddress.csv\"\n",
    "    df_result, statistics = run_recency_analysis(file_path)\n",
    "    \n",
    "    if df_result is not None:\n",
    "        print(f\"\\n=== DETAILED STATISTICS ===\")\n",
    "        print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"DCB_AlternateAddress.csv\"\n",
    "\n",
    "df_with_scores, statistics = run_recency_analysis(file_path)\n",
    "\n",
    "if df_with_scores is not None:\n",
    "    \n",
    "    print(\"\\n=== DETAILED BREAKDOWN FOR FIRST 3 ROWS ===\")\n",
    "    \n",
    "    score_cols = [col for col in df_with_scores.columns if col.endswith('_recency_score')]\n",
    "    \n",
    "    for idx in range(min(3, len(df_with_scores))):\n",
    "        row = df_with_scores.iloc[idx]\n",
    "        print(f\"\\nRow {idx + 1} - {row.get('name', 'Unknown')} ({row.get('email', 'No email')}):\")\n",
    "        \n",
    "        for score_col in score_cols:\n",
    "            if pd.notna(row[score_col]):\n",
    "                addr_idx = score_col.split('.')[1].split('_')[0]\n",
    "                \n",
    "                # Get the address text from new column\n",
    "                addr_text_col = f'Address.{addr_idx}_address_text'\n",
    "                address_text = row.get(addr_text_col, 'N/A')\n",
    "                \n",
    "                delivery_date = row.get(f'Address.{addr_idx}.lastDeliveryDate', 'No date')\n",
    "                times_seen = row.get(f'Address.{addr_idx}.timesSeen', 0)\n",
    "                addr_type = row.get(f'Address.{addr_idx}.addressType', 'Unknown')\n",
    "                \n",
    "                print(f\"  {score_col}: {row[score_col]:.2f}\")\n",
    "                print(f\"    Address: {str(address_text)[:80]}...\")\n",
    "                print(f\"    Last delivery: {delivery_date}\")\n",
    "                print(f\"    Times seen: {times_seen}\")\n",
    "                print(f\"    Type: {addr_type}\")\n",
    "    \n",
    "    print(\"\\n=== CLEAN SUMMARY TABLE ===\")\n",
    "    summary_data = []\n",
    "    \n",
    "    for idx, row in df_with_scores.iterrows():\n",
    "        base_info = {\n",
    "            'Row': idx + 1,\n",
    "            'Name': row.get('name', 'Unknown'),\n",
    "            'Email': row.get('email', 'No email')\n",
    "        }\n",
    "        \n",
    "        has_addresses = False\n",
    "        for score_col in score_cols:\n",
    "            if pd.notna(row[score_col]):\n",
    "                has_addresses = True\n",
    "                addr_idx = score_col.split('.')[1].split('_')[0]\n",
    "                addr_text_col = f'Address.{addr_idx}_address_text'\n",
    "                \n",
    "                row_data = base_info.copy()\n",
    "                row_data.update({\n",
    "                    'Address_Index': f'Address.{addr_idx}',\n",
    "                    'Recency_Score': row[score_col],\n",
    "                    'Address_Text': str(row.get(addr_text_col, 'N/A'))[:60] + '...',\n",
    "                    'Last_Delivery': row.get(f'Address.{addr_idx}.lastDeliveryDate', 'No date'),\n",
    "                    'Times_Seen': row.get(f'Address.{addr_idx}.timesSeen', 0)\n",
    "                })\n",
    "                summary_data.append(row_data)\n",
    "        \n",
    "        if not has_addresses:\n",
    "            summary_data.append(base_info)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(summary_df.head(20).to_string(index=False))\n",
    "    \n",
    "    # Save complete results to CSV\n",
    "    output_file = \"DCB_AlternateAddress_with_recency_scores.csv\"\n",
    "    df_with_scores.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✅ Complete results saved to: {output_file}\")\n",
    "    \n",
    "    # Create and save clean final dataframe with only essential columns\n",
    "    essential_cols = ['email']\n",
    "    \n",
    "    # Add all recency score and address text columns\n",
    "    score_cols = [col for col in df_with_scores.columns if col.endswith('_recency_score')]\n",
    "    address_cols = [col for col in df_with_scores.columns if col.endswith('_address_text')]\n",
    "    \n",
    "    # Combine in pairs (score, address) for each address index\n",
    "    for i in range(10):  # Check up to Address.9\n",
    "        score_col = f'Address.{i}_recency_score'\n",
    "        addr_col = f'Address.{i}_address_text'\n",
    "        if score_col in df_with_scores.columns:\n",
    "            essential_cols.extend([score_col, addr_col])\n",
    "    \n",
    "    # Create clean dataframe\n",
    "    df_clean = df_with_scores[essential_cols].copy()\n",
    "    \n",
    "    # Save clean version\n",
    "    clean_output_file = \"DCB_Recency_Scores_FINAL.csv\"\n",
    "    df_clean.to_csv(clean_output_file, index=False)\n",
    "    print(f\"✅ Clean final dataframe saved to: {clean_output_file}\")\n",
    "    \n",
    "    # Show preview of clean dataframe\n",
    "    print(f\"\\n=== CLEAN FINAL DATAFRAME PREVIEW ===\")\n",
    "    print(f\"Columns: {list(df_clean.columns)}\")\n",
    "    print(f\"Shape: {df_clean.shape}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    for idx, row in df_clean.head().iterrows():\n",
    "        print(f\"\\nRow {idx + 1}: {row['email']}\")\n",
    "        for col in df_clean.columns:\n",
    "            if col.endswith('_recency_score') and pd.notna(row[col]):\n",
    "                addr_idx = col.split('.')[1].split('_')[0]\n",
    "                addr_col = f'Address.{addr_idx}_address_text'\n",
    "                print(f\"  Score: {row[col]:.2f} | Address: {str(row.get(addr_col, 'N/A'))[:50]}...\")\n",
    "    \n",
    "    # Show all new columns created\n",
    "    print(f\"\\n=== NEW COLUMNS CREATED ===\")\n",
    "    new_cols = [col for col in df_with_scores.columns if '_recency_score' in col or '_address_text' in col]\n",
    "    \n",
    "    for col in sorted(new_cols):\n",
    "        if col.endswith('_recency_score'):\n",
    "            non_null_count = df_with_scores[col].count()\n",
    "            avg_score = df_with_scores[col].mean() if non_null_count > 0 else 0\n",
    "            print(f\"{col}: {non_null_count} addresses, avg score: {avg_score:.2f}\")\n",
    "        elif col.endswith('_address_text'):\n",
    "            non_null_count = df_with_scores[col].count()\n",
    "            print(f\"{col}: {non_null_count} address texts\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Analysis failed. Please check your CSV file path and format.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
